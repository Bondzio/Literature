SUMMARY

This study applies genome-wide scans for outliers of Fst to the context of selection components analysis. The focus is on detecting sexual selection imposed by female choice on a male quantitative trait. The male trait subject to female choice is also subject to natural viability selection (a magic trait). A simulation study is performed, in which a genome with a large number of neutral markers and interspersed QTLs for the male trait are is first evolved over a number initial generations to create a certain amount of linkage (dis)equilibrium. A number of generations with sexual selection turned on is then added. Within each of these generations, offspring and adults are sampled, and a weighted and smoothed Fst is calculated for each polymorphic marker between the life stages. Peaks of Fst are arbitrarily classified as “true” and “spurious” based on the distance between the marker and the QTLs. The authors investigate the effect on type I and II error of the initial linkage disequilibrium, sample size, population size, strength of selection, total genome size, number of QTLs, and environmental noise. Interactions for some of these factors are also addressed, as is the effect of sampling multiple equivalent populations.

The main results are that if sexual selection is strong, a majority of the QTLs are detected and false discovery rates are low. However, if selection is spread over a large number of QTLs (> 8), the proportion of true QTLs detected decreases substantially. Large sample sizes (>500) are needed to detect at least half of the QTLs, but when sample size is increased much more, returns are diminishing. Small sample sizes (<500) also come at the cost of increased false discovery rates. Last, the power of the approach is maximised if each QTL has its own chromosome and the total genome is large. On the other hand, if all QTLs are squeezed onto a single, short chromosome, fewer than half of the QTLs are detected, and the false discovery rate is slightly inflated. The logistic challenges associated with obtaining sample sizes as high as necessary to detect a substantial proportion of the QTLs are mentioned. Sampling multiple, equivalent, populations alleviates some of the burden. Moderate environmental noise has the counter-intuitive effect of increasing the power to detect QTLs. The reasons behind this remain unidentified. The interaction between strength of selection and extent of initial LD is not addressed, neither is the effect of the tuning parameter used to determine if a peak is true or spurious.

The analyses carried out seem sound, and there description is mostly accurate and should allow reproduction (see detailed comments for exceptions). The text is very well written, concise and comprehensive. However, I think there are a number of conceptual shortcomings (details below) and the relevance of the paper might be below the statements made in the Introduction. The essential contribution of this study is to apply existing Fst outlier approaches to the context of selection components analysis. The framework of selection components analysis per se is not extended very much. In fact, tracking Fst rather than genotypes or allele frequencies (as was done in previous studies) might actually resemble to a loss of information. On the other hand, important questions about the performance of outlier approaches have been addressed before in the population genomics literature and are merely readdressed here in a slightly different context. I am afraid the article might fall short of innovation and general interest to be published in Molecular Ecology. In any case, substantial extension of the scope of the analyses would seem to enhance the paper a lot, and potentially make it appropriate for publication in this journal. I make several specific suggestions below.



GENERAL COMMENTS

It is well established that outlier tests are not designed for situations where the trait(s) under selection are highly polygenic or when selection is ‘pervasive’ across the genome (e.g. Bierne et al. 2013). It is therefore expected that the authors find a negative correlation between statistical power and number of QTLs (see also Discussion of Lotterhos and Whitlock 2014 and references therein).

Previous work has already shown that sampling design and population size affect the power and false discovery rate of outlier tests, mainly via the shape of the distribution of Fst at neutral sites, which is the null distribution (e.g. Beaumont and Nichols 1996; Lotteries, personal communication). The distribution of Fst at neutral sites is mainly determined by the variance in the coalescence process between unlinked loci. Therefore, to capture the ‘right’ neutral distribution of Fst, it makes more sense to increase the number of neutral markers (genome size in this paper) compared to the sample size. It would hence be interesting to see how genome size and (adult) sample size interact. Could you provide a figure similar to Fig. 2, but with adult sample size varying across panels instead of the number of chromosomes?

Given the large body of literature on detecting Fst outliers, I was expecting some references to these papers (Lewontin and Krakauer 1973, Beaumont and Nichols 1996, Beaumont and Balding 2004, Foll and Gaggiotti 2008). This literature addresses several issues with Fst outlier scans. It is concerned with reliably detecting outliers in a statistical sense and discusses approaches for determining significance. Although I very much favour the idea of using the genome-wide distribution of Fst a the null distribution, I am uneasy with the fact that this distribution was assumed to be Gaussian. Previous literature (e.g. Beaumont and Nichols 1996, Lotterhos and Whitlock 2014) suggests that the distribution is close to a Chi-squared distribution with the degree of freedom being related to the number of populations (here, life stages). This also seems theoretically plausible, given that Fst is the ratio of sums of squared, approximately normally distributed, quantities (the allele frequencies). Could you provide figures showing the observed distributions of Fst in your case? In case of substantial deviation from a Gaussian distribution, I would like to see the genome-wide confidence interval approach modified such as to use the Chi-squared distribution. Alternatively, I suggest using an empirical p-value as threshold (i.e. the 95% or 99% percentile of the empirical distribution). You could split this further into an ‘idealised’ and a ‘realistic’ scenario. In the former, you would compute the empirical p-value from the truly neutral markers only (which you know in a simulation study). In the latter, you would assume know prior knowledge about which sites are neutral, hence include the true QTLs/markers when building the null distribution (cf. Lotterhos and Whitlock 2014). 

I had a major concern about results being shown mostly for a ‘best-case’ scenario. This refers to the choice of LD (nr. of initial generations) and strength of selection (omega_SI = 2) which was made to maximise the power of the outlier approach. I would like to see figures analogous to Figs. 2, 3, 4, an 6 for other choices of LD and omega_SI (in the supplementary information), and an appropriate discussion of the effects. I am asking this because the interplay of recombination/LD and strength of selection must drive the power of outlier approaches to a great extent.

Another concern was about the choice of the distance from the QTL beyond which you classify a maker as ‘spurious’. This seems to be a major tuning parameter for all the analyses performed here. Markers that you define as ‘spurious’ might in fact also be affected by ‘linked selection’. Hence, the false discovery rate might be inflated, or at least have to be interpreted differently. The choice of the threshold distance must interact to a large extent with the number of initial generations (and the initial LD; see previous point), and this interaction will affect power and sensitivity of the outlier approach.

Related to the previous point, the importance of a threshold distance is somewhat debatable in view of application to real data. Candidate regions found via peaks of Fst (both true and spurious ones) would have to be subject to functional studies, experimental tests, or a QTL mapping approach / GWAS if phenotypes are known. One might therefore be much less concerned about false discovery (i.e. inclusion of spurious peaks) than about false negatives (i.e. missing true peaks). 

Sexual selection is modelled as female choice on a male trait, where the mail trait is a magic trait; the very same trait is the target of female choice and natural (viability) selection in males. Because the genetic architecture is then also shared between the sexual and ecological aspect of selection, I suspect that this is the scenario where outlier approaches have highest power in detecting the QTLs for the component of selection of interest. Would it be possible in your framework to separate the trait upon which female preference acts from the trait subject to viability selection? How would that affect the power of your approach?

Related to the previous point, if you increase the strength of viability selection, but decrease the strength of female choice, how does this affect your results?

The theoretical underpinnings of Fst between life stages within a generation are not well established (as compared to the original setting of population structure). While Fst might still be used as a statistic, I think it is at risk of unnecessarily blurring information in the context of selection component analysis. I think that alternative approaches, such as following genotypes and their within-generation frequency changes over multiple generations might be more powerful. I am not asking the authors to look further into this, but would like to see a respective comment in their Discussion. Another reservation against using Fst to detect components of (sexual) selection is that it is highly sensitive to various other modes of selection (background selection, positive selection). Although these modes are more often studied on a cross-generational level, they must also be apparent on a within-generation basis if the two sampling points bracket the time when selection acts.

Although the data and source code are listed as supplementary data, they were not available for review.



SPECIFIC COMMENTS


Abstract:

- l. 7: Mention that the target of mate choice was a quantitative trait.
- l. 13—15: Was the genome-wide average Fst much higher for a small number of chromosomes than for a large one?


Introduction:

- l. 28—29: “[…], ecological factors (Loehle and Pechmann 1988), and can even […]” -> “[…] or ecological factors acting as agents of selection (Loehle and Pechmann 1988). They can also […]”
- l. 30—32: In the Discussion, could you work out the benefit of your analysis for the quantitative genetics theory used in empirical studies? That link was not immediately clear to me.
- l. 44—50: I was a bit confused by the argument that population genomics (outlier) approaches do not facilitate a diagnosis of the type of selection, when, at the same time, you seem to borrow your approach exactly from this domain. The only difference is that you apply the outlier approach to two life stages (vertical or temporal comparison), rather than to a set of populations (horizontal or spatial comparison).
- l. 67—76: The readability of this section is hindered by large numbers of references. Could you do with fewer, key references?
- l. 79–84: I find this an overstatement of the contribution of the paper. Although the work presented here lifts selection components analysis onto the genomic scale, the promise for detecting genome-wide signatures of strong selection is not at all novel, and to some extent compromised. Population genomic studies have long before explored the potential and limits of outlier approaches. The idea of inference about selection without needing to target a trait of interest is also deeply “population genetic”. But it is sold as part of the novelty contributed by this paper. A more humble, justified statement would be that you apply existing population genomic approaches to the context of selection components analysis.
- l. 91—92: “environmental effect” -> “environmental noise”
- l. 102: Shorten subtitle by removing “Specifics of the model:” [the same applies to l. 133]
- l. 103—104: I do not think it is necessary to define diploidy for the targeted readership
- l. 104—105: This sentence read strange to me. What exactly do you mean by “QTLs were randomly placed, but close to one marker”. Please be more explicit.
- l. 109–111: I am not sure if I could reproduce your algorithm from this description. Could you give some more details?
- l. 112: “deteriorated” -> “decayed”
- l. 126: Delete “then”
- l. 127—128: “frequency of alleles i and j occurring together in the population” -> “frequency of the A_iB_j haplotype”
- l. 135—144: It was not clear to me whether the cost to female choosiness (they did not mate if they did not encounter an acceptable mate in 50 trials) was of any relevance. Does it have a consequence on the QTL frequencies responsible for the male trait? If so, this effect should be discussed, and the consequence of variation in female choosiness analysed.
- l. 144—145: In the absence of mutation, and with theta = constant, would the strength of selection decay in the long term?
- l. 143 and 157: I presume there is a tension between theta = 4 (optimum favoured by females) and theta = 0 (natural viability selection) in the sense that if the difference is increased, natural selection counteracts sexual selection more, and vice versa. From the results presented, I did not obtain a good understanding of the importance of this tension and how it varies with increasing contrast between sexual and natural selection optima. Did you explore this?
- l. 160—161: “If an individual is affected by viability selection […] to the next generation.”: I found this a suboptimal formulation and would use a probabilistic formulation similar to l. 145—147.
- l. 170: Delete “Specifics of the model:” (see comment to l. 102)
- l. 186: “variable” -> “polymorphic”
- l. 188: For clarity, I suggest adding indices k and d to the Fst symbols in the formula, as appropriate.
- l. 190: Isn’t sigma_s equal to *half* the window region?
- l. 208: As mentioned above (General comments), I would advocate the use of empirical p-values (percentiles) rather than assuming that the distribution of Fst is Gaussian.


Results

- In general, I missed attempts at explaining some of the more surprising results, e.g. the effect of moderate environmental noise, or the pure performance of the false-discovery rate method used to determine significance. Do you have intuitions for these results? If so, please add a sentence at respective positions.
- l. 239: does “linkage disequilibrium” here refer to “long-range” or “pairwise” LD?
- l. 239—240: As mentioned above, you seem to focus on the best-case scenario here (choosing 200 initial generations). Certainly, that choice must be affected by the strength of selection and this should be addressed. Also, I would like to see figures similar to the ones presented, but for other (marginal) values of initial LD.
- l. 308—310: This is a well-established, more general population genetic observation. I suggest referring to the corresponding literature (see General comments).
- l. 329—332: Is there some intuitive explanation for the effect of V_E?


Discussion

- l. 349—350: I think you should mention the constraints here, too (large sample sizes needed, limitation to small numbers of QTLs). You should also mention early on in the Discussion that you focussed your analyses on the best-case scenario in terms of strength of selection and initial LD.
- l. 357—360: You should acknowledge previous efforts to improve significance tests by leveraging the genome-wide empirical distribution of Fst (e.g. Lotterhos and Whitlock 2014).
- l. 383: As mentioned above (General comments), I find the low power more of an issue than the low type I error rate in this context. If candidate regions are further investigated (QTL mapping, GWAS, functional studies, experiments), I think it is less of a problem to include more false positives, but it is not great to have low power.
- l. 403: “implemented in” -> “applied to”
- l. 406—408: Reaching for large sample sizes in small populations might conflict with conservational concerns, however, if sampling cannot be done in a non-invasive manner. This seems worth a note.
- l. 409—413: As mentioned above (General comments), I found it one of the major conceptual shortcomings that the effect of varying the threshold distance beyond which a peak was declared ’spurious’ was not investigated. It must be a crucial tuning parameter.
- l. 416—418: Again, selection has to be very strong, and I think you should mention this in the conclusion.


References

- l. 449: Please italicise “peromyscus manipulates” and use uppercase P.
- l. 453: “blonde d’aquitaine” -> “Blonde d’Aquitaine” (?)
- l. 500: “FlintJ” -> “Flint J”
- l. 559: “rad” -> “RAD”


Data Accessibility

- I would have appreciated if data and source code were available for review.


Tables

- l. 598: Please correct indices to “omega” in the case of “Experimental mate choice strength” (SI -> SE) and “Initial viability selection strength” (VE -> VI)
- l. 604: Add space before “10 replicates”
- l. 611: Formally, “omega_SI^2 = random mating” read strange to me


Figure captions

- In general, captions repeated a lot of redundant methodological details. If these are given in the main text, do not repeat them, and/or refer back to the caption of Fig. 1 for subsequent captions (e.g. “Further details are as in Fig. 1.”).
- l. 680: I was confused by the fact that you did ten replicates, but there are only six panels in Fig. 6 (I would have expected one panel per replicate). Am I missing something?


Figures

- Fig. 1: I found the axes labels, tick labels, and numbers and text in the panels too small.
- Fig. 2: I suggest adding “(nr. of neutral markers)” to the label of the x axis.
- Fig. 5: Are the ‘spurious’ peaks really ‘spurious’ or are they actually affected by ‘linked selection’ even though your threshold distance of 50 marker loci would classify them as spurious? I would like to see a version of this figure for lower initial LD.
- Fig. 6: I would like to see versions of this figure (and an appropriate discussion) for other values of initial LD, other values of r, and strength of selection.


Literature cited

M. A. Beaumont and D. J. Balding. Identifying adaptive genetic divergence among populations from genome scans. Mol. Econ. 13(4):969–980, 2004.

M. A. Beaumont and R. A. Nichols. Evaluating loci for use in the genetic analysis of population structure. Proc. R. Soc. Lond. Biol. 263(1377):1619–1626, 1996.

M. Foll and O. Gaggiotti. A genome-scan method to identify selected loci appropriate for both dominant and codominant markers: A Bayesian perspective. Genetics 180(2):977–993, 2008.

N. Bierne, D. Roze, and J. J. Welch. Pervasive selection or is it…? Why are FST outliers sometimes so frequent? Mol. Ecol. 22(8):2061–2064, 2013.

R. C. Lewontin and J. Krakauer. Distribution of gene frequency as a test of the theory of the selective neutrality of polymorphisms. Genetics 74(1):175–195, 5 1973.

K. E. Lotterhos and M. C. Whitlock. Evaluation of demographic history and neutral parameterization on the performance of Fst outlier tests. Mol. Ecol. 23(9):2178–2192, 2014.