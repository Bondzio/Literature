Remark
------

I am sending a half-finished review, as I was notified that a decision had been reached before I handed in my complete review. Still, I am happy to share the comments I had so far.



Main comments
------------

1) I wonder if the manuscript title could be more specific, e.g. "The impact of DNA marker quantity, quality, and phasing on demographic inference performed with approximate Bayesian computation". The current title is very broad and could result in the paper being misclassified as "another one reiterating known issues with ABC".

2) From the abstract, it is not clear what the main focus of the paper is: studying the impact on ABC performance of i) marker number, quality, and phasing; ii) the complexity of the demographic model; or iii) both. Later it becomes clear that iii) applies, and that the focus is on a small set of demographic models relevant in the context of invasion scenarios.

3) The distinction between using and not using phase information is made by including or excluding linkage-related summary statistics. As a consequence, if the addition of phasing information has a minor benefit, it may be unclear if this because LD information is not important, or because the larger number of summary statistics adds constraints (the curse of dimensionality) which are absent if linkage-related summary statistics are excluded.

4) Assuming that 'good' (i.e. close to statistically sufficient) summary statistics for unphased data have been used, it is not surprising that methods based on the SFS yield similar results. Vice versa, the fact that the two methods agree could be used to argue that the chosen summary statistics are almost sufficient, since the SFS represents the full information (barring LD information; see the previous point).

6) I was concerned about the choice of summary statistics. Since the current procedure involves a few subtle arbitrary steps (e.g. a priorily fixing the number of PLS components to be retained), I wonder if it would be better to a-priorily avoid closely related summary statistics. For instance, instead of starting with three LD-based statistics and multiple theta-estimators, one could start with one of each type. I also wondered if the authors considered alternative algorithms for choosing summary statistics, which might be less sensitive to the number of and correlation patterns among the original candidate statistics (see e.g. Aeschbacher et al. 2012, Genetics).

7) The choice of distance metric and rejection tolerance should be discussed more.

8) Given the previous work assessing the performance of ABC on genome-wide marker data (some of which is discussed in the manuscript), it was unclear to me how and to what extent this manuscript extends our knowledge about the performance of ABC.


Minor comments
--------------

Abstract

l. 31: For clarity, I suggest to mention what the three parameters are in the 3-parameter model.


Introduction

l. 49-50: It would seem appropriate to cite more review papers than just Schraiber & Akey (2015), given the growing number of such articles that reach beyond demographic inference in humans. Reviews on ABC will be discussed later in the manuscript, but it would be good to cite them here, too.


Demographic inference in natural populations of non-model organisims

l. 59: The field has moved to inference under even more complex scenarios then the ones described in Harris & Nielsen (2013). For instance, see Excoffier (2013), Gravel (2013), or Jouganous et al. (2017).

l. 61-62: It would be good to mention why state-of-the-art statistical inference methods applied to human data are currently out of reach for non-human natural populations.

l. 67: "The good news is the genomic revolution has..." -> "The good news is that the genomic revolution has..." (?)

l. 73-74: It does not become clear here that the PSMC does not only require whole-genome sequences, but also phasing non-haploid organisms (in contrast to ABC). The need for phasing is a further limitation worth mentioning here.

l. 81: It would seem good to mention explicitly that inference based on RRL sequencing methods assumes that individual markers are independent. That is, linkage information is ignored.

l. 98: "First, A large..." -> "First, a large..."

l. 99: ABC is not restricted to simulations "using the coalescent". Any type of simulation of a computer model (including forward-in-time population-genetic simulations) can be used.

l. 101-102: This formulation could be misunderstood as meaning that only the simulation(s) with the minimum distance to the observed summary statistics is kept. Instead, most ABC algorithms retain simulations for which the distance is less than a threshold, and hence involve some tolerance. The choice of this tolerance as well as the appropriate distance metric are major issues that should at least be mentioned.

l. 104-105: Perhaps reformulate to something like "Approximate Bayesian computation is a type of rejection algorithm that avoids the explicit calculation of likelihoods. It is therefore of interest for inference under models for which the likelihood function is hard to compute or intractable."

l. 106: "required" -> "requires"


Previous work exploring the ABC method

l. 116-117: I suggest Blum et al. (2013, Statistical Science, doi:10.1214/12-STS406) and references therein for further literature relevant to the choice of summary statistics.

l. 135: I suggest adding a sentence about other important issues with ABC that the reader should be aware of, but that are beyond the scope of the paper (choice of summary statistics, choice of rejection tolerance, and choice of distance metric). The choice of summary statistics seems particularly important, since different choices of molecular markers and RRL methods may require different sets of summary statistics.


General model and datasets

l. 139: Please refer to Fig. 1 here already.

l. 150-151: It seems that the overestimates of divergence time are a consequence of ignoring linkage information (i.e. of assuming independence of markers). If so, it would be worth stating this here to motivate your use of linkage information.

l. 152-154: This may be beyond the scope of the current manuscript, but a comparison of your ABC method to ABLE (Reddy et al. 2016, https://doi.org/10.1101/077958) would seem interesint. The ABLE method includes linkage information by computing the SFS of blocks of DNA, rather than single SNPs.


Demographic models

l. 163: I suggest to define N_02 on the fly here by replacing "...is created by 2 migrants from population 1" by "...is created by N_02 = 2 migrants from population 1". I also suggest to replace "migrants" by "founder individuals", just to separate colonisation from continuous migration introduced later.

l. 165: If r should denote the rate of expansion forward in time, it is defined by r = log(N_2/N_02)/T_EXP, not by r = log(N_02/N_2)/T_EXP. Currently, r is negative for N_2 > N_02, and hence effectively describes population shrinkage.

l. 170: Although you define them in Table 1, I suggest specifying here that all priors are uniform on a natural scale.

l. 172: Here or perhaps better in the Discussion, it would be good if you could state your believes about generation time in trees.


Genomic datasets simulated

l. 182-184: I suggest to mention here that scrm makes two approximations when simulating the coalescent with recombination (postponing of recombination events on non-local branches; ignoring weak linkage over large genomic regions). In particular, it would be good to state what threshold you used for ignoring weak linkage (see point 3 in Materials and Methods of Staab et al. 2015), and whether this threshold is relevant at all given the lengths of your markers.


Summary statistics

l. 195-196: Please include a short description of what the summary statistics Zns, dvk, and dvh are. It would also be nice if you could briefly mention their main distinctive features.

l. 199: If the mean and variance of a statistic are each counted as a statistic, I wondered how there could be 55 statistics (i.e. an odd number) in the case of phased data.


Validation

l. 220: "i=1000 datasets were simulated" -> "A total of i = 1000 datasets were simulated".

l. 221: "prior ranges" -> "prior distributions"

l. 221: "were estimated for each of them with unchanged settings" -> "were estimated using the default settings of ABCtoolbox".

l. 223: "...simulations, following equation (1):" -> "...simulations as follows:"

l. 224: There should be an index i to \hat{\theta}.

l. 225: "...where theta^{\ast} is the parameter value used for the simulation..." -> "where theta^{\ast} is the parameter value used to generate the POD, and \hat{\theta} is the posterior point estimate of the parameter for the ith valiation simulation."

l. 230: There should be an index i to \hat{\theta}.

l. 224 and 230: I suggest using different symbols for the RMSE and RPE.




Figure and table captions

Table 1: Please define U(a:b) as meaning a uniform distribution between a and b. Note that a more common notation is U(a, b). It would also be good to clarify if R is the per-base pair or per-marker recombination rate.


Supplemental materials and methods

l. 6-27: The motivation for using a two-step procedure for the choice of summary statistics, instead of just PLS, was not fully clear. From l. 21-24, one might think that strong correlations among the candidate statistics that could not be handled by PLS were the reason. Please clarify.

l. 8-10: The result of this pairwise-comparison algorithm depends on the order by which summary statistics are competed. Did you test for the sensitivity to this order?

l. 13: It is unclear what “with the strongest association with most parameters” means.

l. 13-15: I suggest not to call these statistics uncorrelated. Given you keep statistics with a pairwise correlations below 0.8 (0.9), these statistics may still be fairly strongly correlated! Perhaps use “number of retained statistics” instead of “number of uncorrelated statistics”, and replace “set of uncorrelated statistics” by “reduced set of statistics”.

l. 19-20: Please justify this consensus. Theoretically, the number of summary statistics emerges from the criterion that the set of summary statistics must be statistically sufficient for inference about the parameters of interest. In practice, this sufficiency criterion must be balanced against the ‘curse of dimensionality’. The optimal solution to this trade-off -- and hence appropriate number of summary statistics -- does not seem immediately obvious.

l. 26-27: It is unclear why lowering the threshold for choosing uncorrelated statistics would solve the problem in general. With a different order of comparison and/or depending on the correlation patterns, the same highly correlated original statistics may survive the pairwise-comparison step and end up causing two highly correlated PLS components.

[I have not reviewed the full manuscript for reasons explained above.]